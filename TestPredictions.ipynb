{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./exercise_40_train.csv\")\n",
    "test = pd.read_csv(\"./exercise_40_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply all preprocessing modifications to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 'x7' and 'x19' to continuous variables\n",
    "train['x7'] = train.x7.str.replace(\"%\",'').astype(np.float64)\n",
    "test['x7'] = test.x7.str.replace(\"%\",'').astype(np.float64)\n",
    "train['x19'] = train.x19.str.replace(\"$\",'').astype(np.float64)\n",
    "test['x19'] = test.x19.str.replace(\"$\",'').astype(np.float64)\n",
    "\n",
    "# drop column 'x39'\n",
    "train.drop('x39',axis=1,inplace=True)\n",
    "test.drop('x39',axis=1,inplace=True)\n",
    "\n",
    "# 'x99': missing data gets its own category\n",
    "train[\"x99\"] = train[\"x99\"].fillna(\"U\")\n",
    "test[\"x99\"] = test[\"x99\"].fillna(\"U\")\n",
    "\n",
    "# 'x3': Set consistent naming convention for days of the week\n",
    "train['x3'] = train['x3'].str[:3]\n",
    "test['x3'] = test['x3'].str[:3]\n",
    "\n",
    "# 'x60': Sort Months into \"Summer\" and \"Winter\"\n",
    "month_map = {\n",
    "        \"February\":\"FebMarApr\",\n",
    "        \"March\":\"FebMarApr\",\n",
    "        \"April\":\"FebMarApr\",\n",
    "        \"May\":\"MayJun\",\n",
    "        \"June\":\"MayJun\",\n",
    "        \"September\":\"SepOctNov\",\n",
    "        \"October\":\"SepOctNov\",\n",
    "        \"November\":\"SepOctNov\"\n",
    "    }\n",
    "train[\"x60\"] = train['x60'].replace(month_map)\n",
    "test[\"x60\"] = test['x60'].replace(month_map)\n",
    "\n",
    "# 'x24': treat missing data as its own category\n",
    "train[\"x24\"] = train[\"x24\"].fillna(\"U\")\n",
    "test[\"x24\"] = test[\"x24\"].fillna(\"U\")\n",
    "\n",
    "# Group states into VeryHigh, High, Medium, Low, and VeryLow risk\n",
    "df = train[[\"x33\",\"y\"]].groupby(by='x33',dropna=False).agg(['mean','count'])\n",
    "df[\"bin\"] = pd.cut(df[(\"y\",\"mean\")], bins=[.03,.105,.13,.16,.19,.34], labels=[\"VeryLow\",\"Low\",\"Medium\",\"High\",\"VeryHigh\"] )\n",
    "state_map = {}\n",
    "for index, row in df.iterrows():\n",
    "    state_map[index] = row.bin.iloc[0]\n",
    "train['x33'] = train['x33'].replace(state_map)\n",
    "test['x33'] = test['x33'].replace(state_map)\n",
    "\n",
    "# 'x77': combine 'toyota', 'buick', 'nissan' into single category.\n",
    "train['x77'] = train[\"x77\"].replace({\"toyota\":\"ToyotaNissanBuick\",\n",
    "                                    \"nissan\":\"ToyotaNissanBuick\",\n",
    "                                    \"buick\":\"ToyotaNissanBuick\"})\n",
    "test['x77'] = test[\"x77\"].replace({\"toyota\":\"ToyotaNissanBuick\",\n",
    "                                    \"nissan\":\"ToyotaNissanBuick\",\n",
    "                                    \"buick\":\"ToyotaNissanBuick\"})\n",
    "# 'x77': treat missing data as its own category\n",
    "train[\"x77\"] = train[\"x77\"].fillna(\"U\")\n",
    "test[\"x77\"] = test[\"x77\"].fillna(\"U\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, standardize all continuous features of training data and use this scale for the testing data. Then fill training and testing NaN's with the meidan value for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = train.loc[:,train.dtypes==np.object].copy()\n",
    "test_cat = test.loc[:,train.dtypes==np.object].copy()\n",
    "train_num = train.loc[:,train.dtypes==np.float64].copy()\n",
    "test_num = test.loc[:,train.dtypes==np.float64].copy()\n",
    "y_train = train.y.copy()\n",
    "\n",
    "# normalize all continuous data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_num)\n",
    "train_num_scal = scaler.transform(train_num)\n",
    "test_num_scal = scaler.transform(test_num)\n",
    "\n",
    "# fill in all missing continuous data with median of training data\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer.fit(train_num_scal)\n",
    "train_num_scal_tf = pd.DataFrame( imputer.transform(train_num_scal), \n",
    "                                 columns = train_num.columns, index = train_num.index )\n",
    "test_num_scal_tf = pd.DataFrame( imputer.transform(test_num_scal), \n",
    "                                 columns = test_num.columns, index = test_num.index )\n",
    "\n",
    "# get dummy variables\n",
    "cat_var_ls = [\n",
    "    'x3_Mon','x3_Tue','x3_Thu','x3_Fri','x3_Sat','x3_Sun',#'x3_Wed',\n",
    "    'x24_male','x24_U',#'x24_female',\n",
    "    'x31_yes',#'x31_no',\n",
    "    'x33_VeryLow','x33_Medium','x33_High','x33_VeryHigh',#'x33_Low',\n",
    "    'x60_January','x60_FebMarApr','x60_MayJun','x60_July','x60_August','x60_SepOctNov',#'x60_December',\n",
    "    'x65_allstate', 'x65_esurance', 'x65_farmers','x65_geico',#'x65_progressive'\n",
    "    'x77_ford','x77_subaru','x77_mercedes','x77_chevrolet','x77_ToyotaNissanBuick',#'x77_U',\n",
    "    'x93_yes',#'x93_no',\n",
    "    'x99_U',#'x99_yes',\n",
    "]\n",
    "train_cat_dum = pd.get_dummies(train_cat)[cat_var_ls]\n",
    "test_cat_dum = pd.get_dummies(test_cat)[cat_var_ls]\n",
    "\n",
    "X_train = pd.concat([train_num_scal_tf,train_cat_dum], axis=1)\n",
    "X_test = pd.concat([test_num_scal_tf,test_cat_dum], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features selected by RFECV\n",
    "glm_rfe = RFECV( LogisticRegression(max_iter=10000),cv=10, scoring='roc_auc',n_jobs=-1)\n",
    "glm_rfe.fit(X_train,y_train)\n",
    "features = X_train.columns[glm_rfe.support_]\n",
    "# fit logistic regression to training data with the selected features\n",
    "glm = LogisticRegression(max_iter=10000)\n",
    "glm.fit(X_train[features],y_train)\n",
    "# predict probabilities for testing data\n",
    "test_preds_glm = glm.predict_proba(X_test[features])[:,1]\n",
    "pd.DataFrame(test_preds_glm).to_csv(\"./glmresults.csv\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For AdaBoost model, encode 'x33' as an ordinal categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x33_categories = [\"VeryLow\",\"Low\",\"Medium\",\"High\",\"VeryHigh\"]\n",
    "enc = OrdinalEncoder(categories = [x33_categories])\n",
    "X_train_rf = X_train.drop([\"x33_VeryLow\",\"x33_Medium\",\"x33_High\",\"x33_VeryHigh\"],axis=1)\n",
    "X_train_rf[\"x33\"] = enc.fit_transform(train.x33.to_numpy().reshape(-1,1)).reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(algorithm=\"SAMME.R\",learning_rate=0.1,n_estimators=750)\n",
    "ada.fit(X_train,y_train)\n",
    "test_preds_ada = ada.predict_proba(X_test)[:,1]\n",
    "pd.DataFrame(test_preds_ada).to_csv(\"./nonglmresults.csv\",index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
